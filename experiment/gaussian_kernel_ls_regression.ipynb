{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ガウスカーネルで最小二乗回帰(l1,l2正則化)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "sys.path.append(os.pardir)\n",
    "from sklearn.datasets import load_boston\n",
    "from tools.models.regressors.gaussian_kernel_l1 import GaussianKernelNorm1\n",
    "from tools.models.regressors.gaussian_kernel_l2 import GaussianKernelNorm2\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "X = boston.data\n",
    "y = boston.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 100 loss 81.85292559824312\n",
      "iter 200 loss 83.15828620509377\n",
      "iter 300 loss 84.40454588624611\n",
      "iter 400 loss 85.63417918866992\n",
      "iter 500 loss 86.8500478072835\n",
      "iter 600 loss 88.04327518412653\n",
      "iter 700 loss 89.22621818543175\n",
      "iter 800 loss 90.39954559983059\n",
      "iter 900 loss 91.57038385868717\n",
      "iter 1000 loss 92.73201446153953\n",
      "iter 1100 loss 93.88349699288561\n",
      "iter 1200 loss 95.01949488660387\n",
      "iter 1300 loss 96.14241108556547\n",
      "iter 1400 loss 97.25221157914633\n",
      "iter 1500 loss 98.34558485991982\n",
      "iter 1600 loss 99.42330816958263\n",
      "iter 1700 loss 100.4908120504565\n",
      "iter 1800 loss 101.5471370560694\n",
      "iter 1900 loss 102.58985186575745\n",
      "iter 2000 loss 103.62434664407307\n",
      "iter 2100 loss 104.64620786045103\n",
      "iter 2200 loss 105.6553991198306\n",
      "iter 2300 loss 106.65040460915455\n",
      "iter 2400 loss 107.63220543038727\n",
      "iter 2500 loss 108.60113682049118\n",
      "iter 2600 loss 109.55898458586466\n",
      "iter 2700 loss 110.50641694239334\n",
      "iter 2800 loss 111.44499860868339\n",
      "iter 2900 loss 112.37442623987775\n",
      "iter 3000 loss 113.29361844684749\n",
      "iter 3100 loss 114.20253340484685\n",
      "iter 3200 loss 115.10339814533513\n",
      "iter 3300 loss 115.99483275268335\n",
      "iter 3400 loss 116.8751251985539\n",
      "iter 3500 loss 117.74706735562455\n",
      "iter 3600 loss 118.60773902784317\n",
      "iter 3700 loss 119.45716857034847\n",
      "iter 3800 loss 120.29552215586813\n",
      "iter 3900 loss 121.12320391497963\n",
      "iter 4000 loss 121.94099306017682\n",
      "iter 4100 loss 122.74837909915647\n",
      "iter 4200 loss 123.54531318067964\n",
      "iter 4300 loss 124.33269517571519\n",
      "iter 4400 loss 125.11098848946446\n",
      "iter 4500 loss 125.87931953532474\n",
      "iter 4600 loss 126.6378473568911\n",
      "iter 4700 loss 127.38711148077093\n",
      "iter 4800 loss 128.12684807772592\n",
      "iter 4900 loss 128.85720223711755\n",
      "iter 5000 loss 129.57897401783345\n",
      "iter 5100 loss 130.29251164959726\n",
      "iter 5200 loss 130.99710730040408\n",
      "iter 5300 loss 131.69289629019772\n",
      "iter 5400 loss 132.38001181159478\n",
      "iter 5500 loss 133.05858492694088\n",
      "iter 5600 loss 133.72874456944925\n",
      "iter 5700 loss 134.3906175480982\n",
      "iter 5800 loss 135.04432855588894\n",
      "iter 5900 loss 135.6900001811785\n",
      "iter 6000 loss 136.3281935021758\n",
      "iter 6100 loss 136.95887094151564\n",
      "iter 6200 loss 137.58187161204262\n",
      "iter 6300 loss 138.19730955556474\n",
      "iter 6400 loss 138.80529681502134\n",
      "iter 6500 loss 139.40594345785865\n",
      "iter 6600 loss 139.99935760080328\n",
      "iter 6700 loss 140.58564543589475\n",
      "iter 6800 loss 141.1649380183572\n",
      "iter 6900 loss 141.73779484919703\n",
      "iter 7000 loss 142.3038329796582\n",
      "iter 7100 loss 142.86315114908248\n",
      "iter 7200 loss 143.41584631520644\n",
      "iter 7300 loss 143.9620136846463\n",
      "iter 7400 loss 144.50174674371064\n",
      "iter 7500 loss 145.03513728941746\n",
      "iter 7600 loss 145.56227546064144\n",
      "iter 7700 loss 146.08324976930646\n",
      "iter 7800 loss 146.5981471315813\n",
      "iter 7900 loss 147.10705289897132\n",
      "iter 8000 loss 147.61005088928476\n",
      "iter 8100 loss 148.10722341741234\n",
      "iter 8200 loss 148.59945501379178\n",
      "iter 8300 loss 149.08747040450362\n",
      "iter 8400 loss 149.5699455760935\n",
      "iter 8500 loss 150.046928700547\n",
      "iter 8600 loss 150.51849455960266\n",
      "iter 8700 loss 150.98471662203863\n",
      "iter 8800 loss 151.44574095241256\n",
      "iter 8900 loss 151.90189085798954\n",
      "iter 9000 loss 152.35297945654523\n",
      "iter 9100 loss 152.79900163111472\n",
      "iter 9200 loss 153.24002464468356\n",
      "iter 9300 loss 153.67611461263016\n",
      "iter 9400 loss 154.10733652781587\n",
      "iter 9500 loss 154.53375428518217\n",
      "iter 9600 loss 154.95543070584347\n",
      "iter 9700 loss 155.37242756068758\n",
      "iter 9800 loss 155.78480559348492\n",
      "iter 9900 loss 156.19262454348114\n",
      "iter 10000 loss 156.59594316749934\n",
      "l1 model\n",
      "train MSE : 35.674554166409685\n",
      "test MSE : 34.49226498433621\n",
      "190 / 404\n"
     ]
    }
   ],
   "source": [
    "model = GaussianKernelNorm1(h=1000, c=0.001)\n",
    "model.fit(X_train, y_train)\n",
    "train_mse = model.evaluate(X_train, y_train)\n",
    "test_mse = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"l1 model\")\n",
    "print(f\"train MSE : {train_mse}\")\n",
    "print(f\"test MSE : {test_mse}\")\n",
    "print(f\"{sum(model.coef_ < 1e-9)} / {len(model.coef_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l2 model\n",
      "train MSE : 31.84253706928055\n",
      "test MSE : 31.903000831929845\n",
      "206 / 404\n"
     ]
    }
   ],
   "source": [
    "model = GaussianKernelNorm2(h=1000, c=0.00001)\n",
    "model.fit(X_train, y_train)\n",
    "train_mse = model.evaluate(X_train, y_train)\n",
    "test_mse = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"l2 model\")\n",
    "print(f\"train MSE : {train_mse}\")\n",
    "print(f\"test MSE : {test_mse}\")\n",
    "print(f\"{sum(model.coef_ < 1e-9)} / {len(model.coef_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
